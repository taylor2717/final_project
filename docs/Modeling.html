<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Taylor Burke">

<title>Modeling: Predicting Diabetes from Health Indicators – Diabetes Modeling Project</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-6bd9cfa162949bde0a231f530c97869d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Diabetes Modeling Project</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./EDA.html"> 
<span class="menu-text">EDA</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./Modeling.html" aria-current="page"> 
<span class="menu-text">Modeling</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#load-packages-and-data" id="toc-load-packages-and-data" class="nav-link" data-scroll-target="#load-packages-and-data">Load Packages and Data</a></li>
  <li><a href="#traintest-split" id="toc-traintest-split" class="nav-link" data-scroll-target="#traintest-split">Train/Test Split</a></li>
  <li><a href="#common-recipe-for-modeling" id="toc-common-recipe-for-modeling" class="nav-link" data-scroll-target="#common-recipe-for-modeling">Common Recipe for Modeling</a></li>
  <li><a href="#resampling-setup-and-metric" id="toc-resampling-setup-and-metric" class="nav-link" data-scroll-target="#resampling-setup-and-metric">Resampling Setup and Metric</a></li>
  <li><a href="#classification-tree" id="toc-classification-tree" class="nav-link" data-scroll-target="#classification-tree">Classification Tree</a>
  <ul class="collapse">
  <li><a href="#what-is-a-classification-tree" id="toc-what-is-a-classification-tree" class="nav-link" data-scroll-target="#what-is-a-classification-tree">What is a Classification Tree?</a></li>
  <li><a href="#tree-model-specification-and-grid" id="toc-tree-model-specification-and-grid" class="nav-link" data-scroll-target="#tree-model-specification-and-grid">Tree Model Specification and Grid</a></li>
  <li><a href="#tune-the-tree-using-5-fold-cv-log-loss" id="toc-tune-the-tree-using-5-fold-cv-log-loss" class="nav-link" data-scroll-target="#tune-the-tree-using-5-fold-cv-log-loss">Tune the Tree Using 5-Fold CV (Log-loss)</a></li>
  <li><a href="#select-best-tree-and-evaluate-on-test-set" id="toc-select-best-tree-and-evaluate-on-test-set" class="nav-link" data-scroll-target="#select-best-tree-and-evaluate-on-test-set">Select Best Tree and Evaluate on Test Set</a></li>
  </ul></li>
  <li><a href="#random-forest" id="toc-random-forest" class="nav-link" data-scroll-target="#random-forest">Random Forest</a>
  <ul class="collapse">
  <li><a href="#what-is-a-random-forest" id="toc-what-is-a-random-forest" class="nav-link" data-scroll-target="#what-is-a-random-forest">What is a Random Forest?</a></li>
  <li><a href="#random-forest-specification-and-grid" id="toc-random-forest-specification-and-grid" class="nav-link" data-scroll-target="#random-forest-specification-and-grid">Random Forest Specification and Grid</a></li>
  <li><a href="#tune-the-random-forest-with-5-fold-cv-log-loss" id="toc-tune-the-random-forest-with-5-fold-cv-log-loss" class="nav-link" data-scroll-target="#tune-the-random-forest-with-5-fold-cv-log-loss">Tune the Random Forest with 5-Fold CV (Log-loss)</a></li>
  <li><a href="#select-best-random-forest-and-evaluate-on-test-set" id="toc-select-best-random-forest-and-evaluate-on-test-set" class="nav-link" data-scroll-target="#select-best-random-forest-and-evaluate-on-test-set">Select Best Random Forest and Evaluate on Test Set</a></li>
  </ul></li>
  <li><a href="#final-model-selection" id="toc-final-model-selection" class="nav-link" data-scroll-target="#final-model-selection">Final Model Selection</a></li>
  <li><a href="#fit-final-random-forest-to-the-full-data" id="toc-fit-final-random-forest-to-the-full-data" class="nav-link" data-scroll-target="#fit-final-random-forest-to-the-full-data">Fit Final Random Forest to the Full Data</a></li>
  <li><a href="#confusion-matrix-on-test-set" id="toc-confusion-matrix-on-test-set" class="nav-link" data-scroll-target="#confusion-matrix-on-test-set">Confusion Matrix on Test Set</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Modeling: Predicting Diabetes from Health Indicators</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Taylor Burke </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In this document, I build and compare predictive models for the <strong>Diabetes_binary</strong> outcome using the Diabetes Health Indicators dataset. The goal is to develop a model that can estimate the probability that an individual has diabetes based on health indicators such as BMI, blood pressure, cholesterol, physical activity, and general health.</p>
<p>I focus on two tree-based model families:</p>
<ul>
<li><strong>Classification Tree</strong> – a single decision tree that splits the predictor space using if/else rules.</li>
<li><strong>Random Forest</strong> – an ensemble of many decision trees fit on bootstrap samples.</li>
</ul>
<p>Throughout, I use <strong>log-loss</strong> as the primary performance metric because it evaluates the quality of predicted probabilities, not just hard class labels. Lower log-loss means better calibrated and more accurate probability predictions.</p>
<p>I first create a train/test split, define a common preprocessing recipe, and then tune each model type using 5-fold cross-validation on the training data. Finally, I compare the tuned models on the test set and select one model to deploy via an API.</p>
</section>
<section id="load-packages-and-data" class="level2">
<h2 class="anchored" data-anchor-id="load-packages-and-data">Load Packages and Data</h2>
<p>I start by loading the packages needed for modeling and importing the dataset. The same data used in the EDA document is re-used here so that modeling builds directly on earlier exploration.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load required packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(janitor)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)  <span class="co"># for modeling framework</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Set tidymodels to silence messages</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">tidymodels_prefer</span>()</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Import and clean data (same steps as EDA to keep consistent)</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>diabetes <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"diabetes_binary_health_indicators_BRFSS2015.csv"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">clean_names</span>() <span class="sc">%&gt;%</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">diabetes_binary =</span> <span class="fu">factor</span>(diabetes_binary,</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>                             <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>                             <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"NoDiabetes"</span>, <span class="st">"Diabetes"</span>)),</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">high_bp   =</span> <span class="fu">factor</span>(high_bp,   <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>                       <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"NoHighBP"</span>, <span class="st">"HighBP"</span>)),</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">high_chol =</span> <span class="fu">factor</span>(high_chol, <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>                       <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"NoHighChol"</span>, <span class="st">"HighChol"</span>)),</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">smoker    =</span> <span class="fu">factor</span>(smoker,    <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>                       <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"NonSmoker"</span>, <span class="st">"Smoker"</span>)),</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">phys_activity =</span> <span class="fu">factor</span>(phys_activity, <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>                           <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"NoPA"</span>, <span class="st">"PhysActive"</span>)),</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">diff_walk =</span> <span class="fu">factor</span>(diff_walk, <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>                       <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"NoDiffWalk"</span>, <span class="st">"DiffWalk"</span>)),</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">sex       =</span> <span class="fu">factor</span>(sex,       <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>                       <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Female"</span>, <span class="st">"Male"</span>)),</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">gen_hlth =</span> <span class="fu">factor</span>(gen_hlth,</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>                      <span class="at">levels =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>                      <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Excellent"</span>, <span class="st">"VeryGood"</span>, <span class="st">"Good"</span>,</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>                                 <span class="st">"Fair"</span>, <span class="st">"Poor"</span>)),</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">age    =</span> <span class="fu">factor</span>(age,    <span class="at">ordered =</span> <span class="cn">TRUE</span>),</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">income =</span> <span class="fu">factor</span>(income, <span class="at">ordered =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The code above reads in the data from the project folder, standardizes column names, and recodes the Diabetes_binary variable into a factor with labels “NoDiabetes” and “Diabetes.” This prepares the outcome for classification modeling.</p>
</section>
<section id="traintest-split" class="level2">
<h2 class="anchored" data-anchor-id="traintest-split">Train/Test Split</h2>
<p>I now split the data into a training set (70%) and a test set (30%). I stratify by the outcome to preserve the overall class imbalance in both sets. The training data will be used for model fitting and tuning, and the test data will be used only once at the end for an honest assessment of performance.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split into training and test sets (70/30 split)</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>diabetes_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>diabetes,</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="at">prop =</span> <span class="fl">0.7</span>,</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="at">strata =</span> diabetes_binary</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>diabetes_train <span class="ot">&lt;-</span> <span class="fu">training</span>(diabetes_split)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>diabetes_test  <span class="ot">&lt;-</span> <span class="fu">testing</span>(diabetes_split)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Check class proportions:</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co"># train set</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>diabetes_train <span class="sc">%&gt;%</span> <span class="fu">count</span>(diabetes_binary) <span class="sc">%&gt;%</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="fu">mutate</span>(<span class="at">prop =</span> n <span class="sc">/</span> <span class="fu">sum</span>(n))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 3
  diabetes_binary      n  prop
  &lt;fct&gt;            &lt;int&gt; &lt;dbl&gt;
1 NoDiabetes      152833 0.861
2 Diabetes         24742 0.139</code></pre>
</div>
</div>
<p>These proportions show that approximately the same fraction of “Diabetes” vs.&nbsp;“NoDiabetes” cases is maintained in the training set as in the full data. The strong class imbalance (many more NoDiabetes cases) is preserved, which is important so that the model learns under realistic conditions.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># test set</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>diabetes_test <span class="sc">%&gt;%</span> <span class="fu">count</span>(diabetes_binary) <span class="sc">%&gt;%</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mutate</span>(<span class="at">prop =</span> n <span class="sc">/</span> <span class="fu">sum</span>(n))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 3
  diabetes_binary     n  prop
  &lt;fct&gt;           &lt;int&gt; &lt;dbl&gt;
1 NoDiabetes      65501 0.861
2 Diabetes        10604 0.139</code></pre>
</div>
</div>
<p>The test set exhibits almost identical class proportions. This confirms that stratified splitting worked correctly and that the test set will provide a fair evaluation of model performance in the presence of class imbalance.</p>
</section>
<section id="common-recipe-for-modeling" class="level2">
<h2 class="anchored" data-anchor-id="common-recipe-for-modeling">Common Recipe for Modeling</h2>
<p>To keep preprocessing consistent across model types, I define one recipe that will be reused for both the classification tree and the random forest. This recipe ensures the outcome is a factor, creates dummy variables for categorical predictors, and drops any predictors with zero variance.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define modeling formula</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>model_formula <span class="ot">&lt;-</span> diabetes_binary <span class="sc">~</span> high_bp <span class="sc">+</span> high_chol <span class="sc">+</span> bmi <span class="sc">+</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>smoker <span class="sc">+</span> phys_activity <span class="sc">+</span> gen_hlth <span class="sc">+</span> diff_walk <span class="sc">+</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>age <span class="sc">+</span> income <span class="sc">+</span> sex</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Recipe that keeps factors and creates dummy variables</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>diabetes_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(model_formula, <span class="at">data =</span> diabetes_train) <span class="sc">%&gt;%</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure outcome is factor</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="fu">step_mutate</span>(<span class="at">diabetes_binary =</span> diabetes_binary) <span class="sc">%&gt;%</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create dummy variables for all nominal predictors</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="fu">step_dummy</span>(<span class="fu">all_nominal_predictors</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove predictors with zero variance</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="fu">step_zv</span>(<span class="fu">all_predictors</span>())</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>diabetes_recipe</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="resampling-setup-and-metric" class="level2">
<h2 class="anchored" data-anchor-id="resampling-setup-and-metric">Resampling Setup and Metric</h2>
<p>Next, I set up 5-fold cross-validation on the training data and define log-loss as the primary performance metric.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up 5-fold stratified cross-validation </span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>diabetes_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>diabetes_train,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="at">v =</span> <span class="dv">5</span>,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="at">strata =</span> diabetes_binary</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the metric set with log loss</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>logloss_metric <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(mn_log_loss)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="classification-tree" class="level2">
<h2 class="anchored" data-anchor-id="classification-tree">Classification Tree</h2>
<section id="what-is-a-classification-tree" class="level3">
<h3 class="anchored" data-anchor-id="what-is-a-classification-tree">What is a Classification Tree?</h3>
<p>A classification tree splits the predictor space into regions using a series of if/else rules, such as “Is BMI &gt; 30?” or “Is age category ≥ 8?”. Each terminal node (leaf) corresponds to a region of the predictor space and contains a predicted class probability.</p>
<p>Key ideas:</p>
<ul>
<li><p>Each internal node uses one predictor and one split point to divide the data.</p></li>
<li><p>The tree grows by recursively splitting nodes to improve class separation.</p></li>
<li><p>Terminal nodes contain predicted class labels / probabilities.</p></li>
<li><p>Trees are interpretable, but a single tree can be unstable and prone to overfitting.</p></li>
</ul>
<p>The main hyperparameter I tune for the tree is the cost_complexity (pruning strength), along with optional control over tree depth.</p>
</section>
<section id="tree-model-specification-and-grid" class="level3">
<h3 class="anchored" data-anchor-id="tree-model-specification-and-grid">Tree Model Specification and Grid</h3>
<p>I now define a classification tree specification with tunable hyperparameters and a grid of values to explore.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Classification tree model with tunable cost_complexity</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>tree_spec <span class="ot">&lt;-</span> <span class="fu">decision_tree</span>(</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="at">cost_complexity =</span> <span class="fu">tune</span>(),   <span class="co"># pruning parameter</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="at">tree_depth      =</span> <span class="fu">tune</span>(),</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="at">min_n           =</span> <span class="dv">20</span>        <span class="co"># minimum observations per node</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set_engine</span>(<span class="st">"rpart"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>tree_spec</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Decision Tree Model Specification (classification)

Main Arguments:
  cost_complexity = tune()
  tree_depth = tune()
  min_n = 20

Computational engine: rpart </code></pre>
</div>
</div>
<p>The model specification shows that cost_complexity and tree_depth will be determined via tuning, while min_n is fixed at 20. Using a larger min_n helps avoid extremely small leaves that might overfit.</p>
<p>Create a workflow combining the recipe and model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine the tree specification with the common recipe into a workflow</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>tree_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="fu">add_model</span>(tree_spec) <span class="sc">%&gt;%</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="fu">add_recipe</span>(diabetes_recipe)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>tree_workflow</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>══ Workflow ════════════════════════════════════════════════════════════════════
Preprocessor: Recipe
Model: decision_tree()

── Preprocessor ────────────────────────────────────────────────────────────────
3 Recipe Steps

• step_mutate()
• step_dummy()
• step_zv()

── Model ───────────────────────────────────────────────────────────────────────
Decision Tree Model Specification (classification)

Main Arguments:
  cost_complexity = tune()
  tree_depth = tune()
  min_n = 20

Computational engine: rpart </code></pre>
</div>
</div>
<p>This workflow summary confirms that the tree model will always be fit on preprocessed data from the recipe. Keeping the recipe inside the workflow is a best practice in tidymodels and ensures that all resamples receive identical preprocessing.</p>
<p>Now define a tuning grid for cost_complexity and tree_depth.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a regular grid of cost_complexity and tree_depth values for tuning</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>tree_grid <span class="ot">&lt;-</span> <span class="fu">grid_regular</span>(</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cost_complexity</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="sc">-</span><span class="dv">1</span>)),  <span class="co"># on log10 scale</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="fu">tree_depth</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">3</span>L, <span class="dv">10</span>L)),</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="at">levels =</span> <span class="fu">c</span>(<span class="at">cost_complexity =</span> <span class="dv">5</span>, <span class="at">tree_depth =</span> <span class="dv">4</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>tree_grid</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 20 × 2
   cost_complexity tree_depth
             &lt;dbl&gt;      &lt;int&gt;
 1        0.0001            3
 2        0.000562          3
 3        0.00316           3
 4        0.0178            3
 5        0.1               3
 6        0.0001            5
 7        0.000562          5
 8        0.00316           5
 9        0.0178            5
10        0.1               5
11        0.0001            7
12        0.000562          7
13        0.00316           7
14        0.0178            7
15        0.1               7
16        0.0001           10
17        0.000562         10
18        0.00316          10
19        0.0178           10
20        0.1              10</code></pre>
</div>
</div>
<p>The tuning grid lists all combinations of cost_complexity and tree_depth to be evaluated. Cost complexity spans several orders of magnitude, and tree depths range from shallow (3) to deep (10), allowing the algorithm to explore both simple and complex trees.</p>
</section>
<section id="tune-the-tree-using-5-fold-cv-log-loss" class="level3">
<h3 class="anchored" data-anchor-id="tune-the-tree-using-5-fold-cv-log-loss">Tune the Tree Using 5-Fold CV (Log-loss)</h3>
<p>Using 5-fold cross-validation, I evaluate each combination of cost_complexity and tree_depth in the grid.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Tune the classification tree over the grid using 5-fold CV and log-loss</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>tree_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>tree_workflow,</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="at">resamples =</span> diabetes_folds,</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="at">grid =</span> tree_grid,</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="at">metrics =</span> logloss_metric,</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="at">control =</span> <span class="fu">control_grid</span>(<span class="at">save_pred =</span> <span class="cn">TRUE</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>tree_res</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Tuning results
# 5-fold cross-validation using stratification 
# A tibble: 5 × 5
  splits                 id    .metrics          .notes           .predictions
  &lt;list&gt;                 &lt;chr&gt; &lt;list&gt;            &lt;list&gt;           &lt;list&gt;      
1 &lt;split [142059/35516]&gt; Fold1 &lt;tibble [20 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
2 &lt;split [142059/35516]&gt; Fold2 &lt;tibble [20 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
3 &lt;split [142060/35515]&gt; Fold3 &lt;tibble [20 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
4 &lt;split [142061/35514]&gt; Fold4 &lt;tibble [20 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
5 &lt;split [142061/35514]&gt; Fold5 &lt;tibble [20 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    </code></pre>
</div>
</div>
<p>This output confirms that 5 stratified folds were successfully created. Because each fold preserves the original class proportions, each resample gives a fair estimate of model performance for an imbalanced classification task.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract cross-validated log-loss results for all hyperparameter combinations</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Collect tuning results</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>tree_metrics <span class="ot">&lt;-</span> tree_res <span class="sc">%&gt;%</span> <span class="fu">collect_metrics</span>()</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>tree_metrics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 20 × 8
   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config
             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  
 1        0.0001            3 mn_log_loss binary     0.404     5 9.73e-6 Prepro…
 2        0.000562          3 mn_log_loss binary     0.404     5 9.73e-6 Prepro…
 3        0.00316           3 mn_log_loss binary     0.404     5 9.73e-6 Prepro…
 4        0.0178            3 mn_log_loss binary     0.404     5 9.73e-6 Prepro…
 5        0.1               3 mn_log_loss binary     0.404     5 9.73e-6 Prepro…
 6        0.0001            5 mn_log_loss binary     0.358     5 5.91e-4 Prepro…
 7        0.000562          5 mn_log_loss binary     0.358     5 5.91e-4 Prepro…
 8        0.00316           5 mn_log_loss binary     0.358     5 5.75e-4 Prepro…
 9        0.0178            5 mn_log_loss binary     0.404     5 9.73e-6 Prepro…
10        0.1               5 mn_log_loss binary     0.404     5 9.73e-6 Prepro…
11        0.0001            7 mn_log_loss binary     0.350     5 3.85e-3 Prepro…
12        0.000562          7 mn_log_loss binary     0.357     5 6.38e-4 Prepro…
13        0.00316           7 mn_log_loss binary     0.358     5 6.08e-4 Prepro…
14        0.0178            7 mn_log_loss binary     0.404     5 9.73e-6 Prepro…
15        0.1               7 mn_log_loss binary     0.404     5 9.73e-6 Prepro…
16        0.0001           10 mn_log_loss binary     0.340     5 2.33e-3 Prepro…
17        0.000562         10 mn_log_loss binary     0.357     5 9.28e-4 Prepro…
18        0.00316          10 mn_log_loss binary     0.358     5 6.08e-4 Prepro…
19        0.0178           10 mn_log_loss binary     0.404     5 9.73e-6 Prepro…
20        0.1              10 mn_log_loss binary     0.404     5 9.73e-6 Prepro…</code></pre>
</div>
</div>
<p>This table reports the mean log-loss for each combination of cost complexity and tree depth across the five folds. Small log-loss values indicate better performance. We can already see that deeper trees (depth 10) with very small cost_complexity values achieve the strongest performance, suggesting that the dataset benefits from models capable of capturing more complex interactions among predictors.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot log-loss vs cost_complexity for a few depths</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>tree_metrics <span class="sc">%&gt;%</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> cost_complexity, <span class="at">y =</span> mean,</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="at">color =</span> <span class="fu">factor</span>(tree_depth))) <span class="sc">+</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="fu">scale_x_log10</span>() <span class="sc">+</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="fu">labs</span>(</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="at">title =</span> <span class="st">"Classification Tree: Log-loss vs Cost Complexity"</span>,</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="at">x =</span> <span class="st">"Cost Complexity (log10 scale)"</span>,</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="at">y =</span> <span class="st">"Mean Log-loss (5-fold CV)"</span>,</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="at">color =</span> <span class="st">"Tree Depth"</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Modeling_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The plot visualizes how log-loss changes as we increase cost complexity. For shallow trees, log-loss remains comparatively high regardless of pruning level, indicating underfitting. Deeper trees initially yield lower log-loss when pruning is minimal, but performance worsens as pruning increases. This confirms that the best-performing models are deep trees with very small cost complexity values, aligning with the numeric tuning results above.</p>
</section>
<section id="select-best-tree-and-evaluate-on-test-set" class="level3">
<h3 class="anchored" data-anchor-id="select-best-tree-and-evaluate-on-test-set">Select Best Tree and Evaluate on Test Set</h3>
<p>From the tuning results, I select the tree with the lowest cross-validated log-loss. I then finalize the workflow with these hyperparameters and fit the model on the full training set, evaluating it once on the held-out test set. The resulting test-set log-loss provides an unbiased estimate of how well this tuned classification tree calibrates predicted probabilities for new individuals. Because log-loss is on a different scale than accuracy, I will compare this value directly to the random forest’s test log-loss to decide which overall model performs better.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify the hyperparameter combination that minimizes cross-validated log-loss</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>best_tree <span class="ot">&lt;-</span> tree_res <span class="sc">%&gt;%</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="fu">select_best</span>(<span class="at">metric =</span> <span class="st">"mn_log_loss"</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>best_tree</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 3
  cost_complexity tree_depth .config              
            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                
1          0.0001         10 Preprocessor1_Model16</code></pre>
</div>
</div>
<p>These results show that the optimal tree uses a very small cost complexity value and the maximum tree depth considered. This configuration allows the tree to capture detailed structure in the data while still using slight pruning to avoid extreme overfitting. This tuned tree will now be evaluated on the held-out test set to estimate its real-world performance.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Finalize the tree workflow with the best hyperparameters and fit/evaluate on the test set</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Finalize workflow with best hyperparameters</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>final_tree_workflow <span class="ot">&lt;-</span> tree_workflow <span class="sc">%&gt;%</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="fu">finalize_workflow</span>(best_tree)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit to training data and evaluate on test set</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>tree_final_fit <span class="ot">&lt;-</span> <span class="fu">last_fit</span>(</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>final_tree_workflow,</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="at">split =</span> diabetes_split,</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="at">metrics =</span> logloss_metric</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-loss on test set</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>tree_test_metrics <span class="ot">&lt;-</span> tree_final_fit <span class="sc">%&gt;%</span> <span class="fu">collect_metrics</span>()</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>tree_test_metrics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 4
  .metric     .estimator .estimate .config             
  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
1 mn_log_loss binary         0.347 Preprocessor1_Model1</code></pre>
</div>
</div>
<p>The tuned classification tree achieves a test-set log-loss of approximately 0.347. Because log-loss penalizes confident wrong predictions, this value indicates that while the tree captures meaningful patterns, it still produces some overconfident errors—expected given the dataset’s imbalance and the tree’s high flexibility. This result provides a performance baseline before evaluating more powerful ensemble methods.</p>
</section>
</section>
<section id="random-forest" class="level2">
<h2 class="anchored" data-anchor-id="random-forest">Random Forest</h2>
<section id="what-is-a-random-forest" class="level3">
<h3 class="anchored" data-anchor-id="what-is-a-random-forest">What is a Random Forest?</h3>
<p>A random forest is an ensemble of many classification trees:</p>
<ul>
<li>Each tree is trained on a bootstrap sample (sampling with replacement) of the training data.</li>
<li>At each split, only a random subset of predictors is considered (mtry).</li>
<li>Predictions are aggregated (majority vote for classes, or averaging probabilities).</li>
</ul>
<p>Why use a random forest?</p>
<ul>
<li>Reduces the variance and instability of a single tree.</li>
<li>Often much better predictive performance.</li>
<li>Still somewhat interpretable through variable importance measures.</li>
</ul>
<p>The key tuning parameter here is mtry:</p>
<ul>
<li>Smaller mtry → more randomness between trees, potentially better generalization.</li>
<li>Larger mtry → trees more similar to each other.</li>
</ul>
<p>For this dataset, a random forest can capture complex nonlinear relationships between health indicators and diabetes status by averaging over many different trees. This is especially appealing given the mixture of numeric and categorical predictors and the potential interactions among variables like BMI, high blood pressure, general health, and physical activity. The trade-off is that the random forest is less interpretable than a single tree, so model selection will focus primarily on predictive performance measured via log-loss.</p>
</section>
<section id="random-forest-specification-and-grid" class="level3">
<h3 class="anchored" data-anchor-id="random-forest-specification-and-grid">Random Forest Specification and Grid</h3>
<p>I specify a random forest model with a fixed number of trees and a tunable mtry parameter, which controls how many predictors are considered at each split. Smaller mtry values increase randomness between trees and can improve generalization, while larger mtry values make trees more similar to each other. The grid of mtry values explores different levels of predictor subset size so I can see how much randomness is helpful for this problem. As with the tree, I combine this model specification with the same preprocessing recipe to ensure a fair comparison between modeling approaches.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify a tunable random forest model with mtry as the primary hyperparameter</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>rf_spec <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="at">mtry =</span> <span class="fu">tune</span>(), <span class="co"># number of predictors considered at each split</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="at">trees =</span> <span class="dv">500</span>, <span class="co"># number of trees in the forest</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="at">min_n =</span> <span class="dv">20</span> <span class="co"># minimum node size</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set_engine</span>(<span class="st">"ranger"</span>, <span class="at">importance =</span> <span class="st">"impurity"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>rf_spec</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Random Forest Model Specification (classification)

Main Arguments:
  mtry = tune()
  trees = 500
  min_n = 20

Engine-Specific Arguments:
  importance = impurity

Computational engine: ranger </code></pre>
</div>
</div>
<p>The model specification shows that only mtry will be tuned, while trees and min_n are held fixed. Using 500 trees provides a stable ensemble, and the importance = “impurity” setting allows us to later inspect variable importance if desired.</p>
<p>Workflow:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build a workflow that pairs the random forest specification with the common recipe</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>rf_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="fu">add_model</span>(rf_spec) <span class="sc">%&gt;%</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="fu">add_recipe</span>(diabetes_recipe)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>rf_workflow</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>══ Workflow ════════════════════════════════════════════════════════════════════
Preprocessor: Recipe
Model: rand_forest()

── Preprocessor ────────────────────────────────────────────────────────────────
3 Recipe Steps

• step_mutate()
• step_dummy()
• step_zv()

── Model ───────────────────────────────────────────────────────────────────────
Random Forest Model Specification (classification)

Main Arguments:
  mtry = tune()
  trees = 500
  min_n = 20

Engine-Specific Arguments:
  importance = impurity

Computational engine: ranger </code></pre>
</div>
</div>
<p>This workflow summary confirms that the random forest uses the same preprocessing recipe as the classification tree. This alignment ensures that any performance differences reflect the modeling strategy itself.</p>
<p>Grid for mtry:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a tuning grid over candidate mtry values for the random forest</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of predictor columns after dummies</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>num_pred <span class="ot">&lt;-</span> diabetes_recipe <span class="sc">%&gt;%</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="fu">prep</span>() <span class="sc">%&gt;%</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="fu">juice</span>() <span class="sc">%&gt;%</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="fu">select</span>(<span class="sc">-</span>diabetes_binary) <span class="sc">%&gt;%</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="fu">ncol</span>()</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a simple grid for mtry</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>rf_grid <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="at">mtry =</span> <span class="fu">floor</span>(<span class="fu">seq</span>(<span class="dv">2</span>, num_pred, <span class="at">length.out =</span> <span class="dv">6</span>))</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>rf_grid</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 1
   mtry
  &lt;dbl&gt;
1     2
2     7
3    13
4    18
5    24
6    30</code></pre>
</div>
</div>
<p>The value of num_pred indicates how many predictor columns exist after dummy variables are created. I use this number to construct a sensible range of candidate mtry values.</p>
<p>The mtry grid explores six mtry values from very small to relatively large. Smaller mtry values force more randomness between trees, whereas larger values make trees more similar. The goal is to find the mtry that yields the lowest log-loss.</p>
</section>
<section id="tune-the-random-forest-with-5-fold-cv-log-loss" class="level3">
<h3 class="anchored" data-anchor-id="tune-the-random-forest-with-5-fold-cv-log-loss">Tune the Random Forest with 5-Fold CV (Log-loss)</h3>
<p>I repeat the same 5-fold cross-validation procedure for the random forest, evaluating log-loss for each candidate mtry value. The results indicate which level of predictor subsampling strikes the best balance between bias and variance. In this dataset, the best-performing mtry value corresponds to a model that allows enough randomness to diversify the trees while still considering a reasonable number of predictors at each split. Compared to the single tree, the random forest tends to achieve lower log-loss, reflecting its ability to average over many decision boundaries and reduce overfitting.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Tune the random forest over the mtry grid using 5-fold CV and log-loss</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>rf_res <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>rf_workflow,</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="at">resamples =</span> diabetes_folds,</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="at">grid =</span> rf_grid,</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="at">metrics =</span> logloss_metric,</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="at">control =</span> <span class="fu">control_grid</span>(<span class="at">save_pred =</span> <span class="cn">TRUE</span>)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>rf_res</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># Tuning results
# 5-fold cross-validation using stratification 
# A tibble: 5 × 5
  splits                 id    .metrics         .notes           .predictions
  &lt;list&gt;                 &lt;chr&gt; &lt;list&gt;           &lt;list&gt;           &lt;list&gt;      
1 &lt;split [142059/35516]&gt; Fold1 &lt;tibble [6 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
2 &lt;split [142059/35516]&gt; Fold2 &lt;tibble [6 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
3 &lt;split [142060/35515]&gt; Fold3 &lt;tibble [6 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
4 &lt;split [142061/35514]&gt; Fold4 &lt;tibble [6 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    
5 &lt;split [142061/35514]&gt; Fold5 &lt;tibble [6 × 5]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    </code></pre>
</div>
</div>
<p>The tuning results confirm that each mtry value was evaluated using 5-fold stratified cross-validation, giving a reliable estimate of performance for each configuration.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Summarize cross-validated log-loss for each candidate mtry value</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>rf_metrics <span class="ot">&lt;-</span> rf_res <span class="sc">%&gt;%</span> <span class="fu">collect_metrics</span>()</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>rf_metrics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 7
   mtry .metric     .estimator  mean     n  std_err .config             
  &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               
1     2 mn_log_loss binary     0.327     5 0.000455 Preprocessor1_Model1
2     7 mn_log_loss binary     0.325     5 0.000665 Preprocessor1_Model2
3    13 mn_log_loss binary     0.333     5 0.00110  Preprocessor1_Model3
4    18 mn_log_loss binary     0.339     5 0.00158  Preprocessor1_Model4
5    24 mn_log_loss binary     0.347     5 0.00252  Preprocessor1_Model5
6    30 mn_log_loss binary     0.361     5 0.00245  Preprocessor1_Model6</code></pre>
</div>
</div>
<p>The metrics table shows mean log-loss for each mtry value. The smallest log-loss occurs near mtry = 7, with performance worsening as mtry increases. This suggests that moderate randomness in predictor selection leads to the best generalization.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot mean log-loss against mtry to visualize the best-performing random forest configuration</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>rf_metrics <span class="sc">%&gt;%</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> mtry, <span class="at">y =</span> mean)) <span class="sc">+</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="fu">labs</span>(</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="at">title =</span> <span class="st">"Random Forest: Log-loss vs mtry"</span>,</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="at">x =</span> <span class="st">"mtry"</span>,</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="at">y =</span> <span class="st">"Mean Log-loss (5-fold CV)"</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Modeling_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The plot reinforces the table: the lowest mean log-loss is achieved when mtry is small. As mtry increases, log-loss rises, showing that using too many predictors at each split reduces the benefits of randomization.</p>
</section>
<section id="select-best-random-forest-and-evaluate-on-test-set" class="level3">
<h3 class="anchored" data-anchor-id="select-best-random-forest-and-evaluate-on-test-set">Select Best Random Forest and Evaluate on Test Set</h3>
<p>As with the classification tree, I select the random forest configuration with the lowest cross-validated log-loss and refit it on the full training set. Evaluating this finalized model on the test set yields a test log-loss that can be compared directly to the tuned tree’s test log-loss. Because both models use the same train/test split, recipe, and evaluation metric, any difference in performance can be attributed to the modeling approach itself rather than to differences in data processing.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Choose the random forest hyperparameters that minimize cross-validated log-loss</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>best_rf <span class="ot">&lt;-</span> rf_res <span class="sc">%&gt;%</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="fu">select_best</span>(<span class="at">metric =</span> <span class="st">"mn_log_loss"</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>best_rf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 2
   mtry .config             
  &lt;dbl&gt; &lt;chr&gt;               
1     7 Preprocessor1_Model2</code></pre>
</div>
</div>
<p>The selected mtry value (here, mtry = 7) is the configuration that delivered the lowest cross-validated log-loss. This choice strikes a good balance between tree diversity and predictive strength.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Finalize the random forest workflow with the best mtry and evaluate it on the test set</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>final_rf_workflow <span class="ot">&lt;-</span> rf_workflow <span class="sc">%&gt;%</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="fu">finalize_workflow</span>(best_rf)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>rf_final_fit <span class="ot">&lt;-</span> <span class="fu">last_fit</span>(</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>final_rf_workflow,</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="at">split =</span> diabetes_split,</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="at">metrics =</span> logloss_metric</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute log-loss on the held-out test data for the tuned random forest</span></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>rf_test_metrics <span class="ot">&lt;-</span> rf_final_fit <span class="sc">%&gt;%</span> <span class="fu">collect_metrics</span>()</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>rf_test_metrics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 4
  .metric     .estimator .estimate .config             
  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
1 mn_log_loss binary         0.325 Preprocessor1_Model1</code></pre>
</div>
</div>
<p>On the held-out test set, the tuned random forest achieves the log-loss reported in the table (around 0.325). This is lower than the classification tree’s log-loss, indicating that the forest provides better calibrated probability predictions for diabetes status.</p>
</section>
</section>
<section id="final-model-selection" class="level2">
<h2 class="anchored" data-anchor-id="final-model-selection">Final Model Selection</h2>
<p>Now that both model families have been tuned and evaluated on the test set, I place their results side-by-side to choose the overall winner.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare test-set log-loss for the tuned tree and tuned random forest to choose the final model</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine test metrics for comparison</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>model_compare <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>tree_test_metrics <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">"Classification Tree"</span>),</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>rf_test_metrics   <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">"Random Forest"</span>)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="fu">relocate</span>(model)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>model_compare</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 5
  model               .metric     .estimator .estimate .config             
  &lt;chr&gt;               &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
1 Classification Tree mn_log_loss binary         0.347 Preprocessor1_Model1
2 Random Forest       mn_log_loss binary         0.325 Preprocessor1_Model1</code></pre>
</div>
</div>
<p>This comparison table clearly shows that the random forest has lower test-set log-loss than the classification tree. Because both models were trained and evaluated using the same data splits and metric, the difference reflects a genuine performance advantage. I therefore select the random forest as the final model to deploy.</p>
</section>
<section id="fit-final-random-forest-to-the-full-data" class="level2">
<h2 class="anchored" data-anchor-id="fit-final-random-forest-to-the-full-data">Fit Final Random Forest to the Full Data</h2>
<p>After selecting the random forest as the best model, I refit it on the full dataset (training plus test data) using the chosen hyperparameters. This final fit uses all available information to learn the relationship between predictors and diabetes status, which is important for deployment: the API will use this version of the model to generate predictions for new individuals. Because the model choice and evaluation were already made using a separate test set, refitting on the full data does not bias the earlier comparison but does maximize the data used for the final model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Refit the chosen random forest on the full dataset to create the deployment model</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Reuse the recipe, now prepping it on the full data</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>final_recipe_full <span class="ot">&lt;-</span> diabetes_recipe <span class="sc">%&gt;%</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="fu">prep</span>(<span class="at">training =</span> diabetes)</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>final_rf_fit_full <span class="ot">&lt;-</span> final_rf_workflow <span class="sc">%&gt;%</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="fu">fit</span>(<span class="at">data =</span> diabetes)</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>final_rf_fit_full</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>══ Workflow [trained] ══════════════════════════════════════════════════════════
Preprocessor: Recipe
Model: rand_forest()

── Preprocessor ────────────────────────────────────────────────────────────────
3 Recipe Steps

• step_mutate()
• step_dummy()
• step_zv()

── Model ───────────────────────────────────────────────────────────────────────
Ranger result

Call:
 ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~7,      x), num.trees = ~500, min.node.size = min_rows(~20, x), importance = ~"impurity",      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1), probability = TRUE) 

Type:                             Probability estimation 
Number of trees:                  500 
Sample size:                      253680 
Number of independent variables:  30 
Mtry:                             7 
Target node size:                 20 
Variable importance mode:         impurity 
Splitrule:                        gini 
OOB prediction error (Brier s.):  0.09975817 </code></pre>
</div>
</div>
<p>The printed workflow confirms that the final random forest (500 trees, mtry = 7) has been trained on the full dataset. Training on all observations allows the final model to capture as much information as possible while still benefiting from the prior model selection process carried out on a separate test set.</p>
</section>
<section id="confusion-matrix-on-test-set" class="level2">
<h2 class="anchored" data-anchor-id="confusion-matrix-on-test-set">Confusion Matrix on Test Set</h2>
<p>Although log-loss is the primary performance metric, it is also useful to examine a confusion matrix for the test set using a 0.5 probability cutoff. This provides insight into how often the model correctly identifies individuals with and without diabetes.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Collect predictions on test set from last_fit</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>rf_test_preds <span class="ot">&lt;-</span> rf_final_fit <span class="sc">%&gt;%</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="fu">collect_predictions</span>()</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Hard classification using 0.5 cutoff on Diabetes probability</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>rf_test_preds <span class="ot">&lt;-</span> rf_test_preds <span class="sc">%&gt;%</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="fu">mutate</span>(</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="at">.pred_class =</span> <span class="fu">if_else</span>(.pred_Diabetes <span class="sc">&gt;=</span> <span class="fl">0.5</span>,</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="st">"Diabetes"</span>, <span class="st">"NoDiabetes"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a><span class="fu">factor</span>(<span class="at">levels =</span> <span class="fu">levels</span>(diabetes<span class="sc">$</span>diabetes_binary))</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix</span></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>rf_conf <span class="ot">&lt;-</span> rf_test_preds <span class="sc">%&gt;%</span></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a><span class="fu">conf_mat</span>(<span class="at">truth =</span> diabetes_binary, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>rf_conf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Truth
Prediction   NoDiabetes Diabetes
  NoDiabetes      64094     8978
  Diabetes         1407     1626</code></pre>
</div>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(rf_conf, <span class="at">type =</span> <span class="st">"heatmap"</span>) <span class="sc">+</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="fu">scale_fill_gradient</span>() <span class="sc">+</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="fu">labs</span>(</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="at">title =</span> <span class="st">"Confusion Matrix: Final Random Forest (Test Set)"</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Modeling_files/figure-html/confusion-matrix-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Confusion Matrix for Final Random Forest on Test Set</figcaption>
</figure>
</div>
</div>
</div>
<p>Numerically, the confusion matrix shows that the model correctly classifies most NoDiabetes cases (true negatives) while also identifying a meaningful number of Diabetes cases (true positives). However, there are still both false negatives (missed diabetes cases) and false positives. This reflects the challenge posed by the substantial class imbalance in the data.</p>
<p>The heatmap visually highlights the same pattern: a large block of correctly predicted non-diabetes cases and a smaller but still visible block of correctly predicted diabetes cases. The off-diagonal cells represent misclassifications, reminding us that even though the random forest performs best according to log-loss, it is not perfect and should be interpreted with care in practice.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<ul>
<li><p>I split the data into a 70/30 train/test split, preserving the strong class imbalance via stratification.</p></li>
<li><p>I used a common recipe to preprocess predictors (dummy variables, zero-variance filtering) for both models.</p></li>
<li><p>I tuned:</p>
<ul>
<li><p>A classification tree over cost_complexity and tree_depth.</p></li>
<li><p>A random forest over mtry.</p></li>
</ul></li>
<li><p>Both models were tuned using 5-fold cross-validation with log-loss as the primary metric.</p></li>
<li><p>On the held-out test set, the random forest achieved a lower log-loss than the classification tree, indicating better calibrated probability predictions for diabetes risk.</p></li>
<li><p>I refit the final random forest on the full dataset to create a deployment-ready model and evaluated its classification behavior using a confusion matrix.</p></li>
</ul>
<p>In the next step of the project, this final random forest model is used in a plumber API and served through a Docker container, allowing external users to submit new patient profiles and obtain estimated probabilities of diabetes.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>